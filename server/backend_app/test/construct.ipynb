{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 22.05417529170841\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "import sqlite3\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import category_encoders as ce\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "import dill\n",
    "from tpot import TPOTRegressor, TPOTClassifier\n",
    "\n",
    "def select_algorithm(operation_type, algorithm_name='AUTO_ML', **kwargs):\n",
    "    if algorithm_name == 'AUTO_ML':\n",
    "        if operation_type.upper() == \"PREDICTION\":\n",
    "            tpot_regressor = TPOTRegressor(generations=5, population_size=20, verbosity=2)\n",
    "            return tpot_regressor\n",
    "        elif operation_type.upper() == \"CLASSIFICATION\":\n",
    "            tpot_classifier = TPOTClassifier(generations=5, population_size=20, verbosity=2)\n",
    "            return tpot_classifier\n",
    "    else:\n",
    "        prediction_algorithms = {\n",
    "            \"LR\": LinearRegression(),\n",
    "            \"RF\": RandomForestRegressor(),\n",
    "            \"SVR\": SVR(),\n",
    "            \"KNN\": KNeighborsRegressor(),\n",
    "            \"GB\": GradientBoostingRegressor(),\n",
    "        }\n",
    "        classification_algorithms = {\n",
    "            \"LOG\": LogisticRegression(),\n",
    "            \"RFC\": RandomForestClassifier(),\n",
    "            \"SVC\": SVC(),\n",
    "            \"KNN\": KNeighborsClassifier(),\n",
    "            \"GBC\": GradientBoostingClassifier(),\n",
    "        }\n",
    "        clustering_algorithms = {\n",
    "            \"KMEANS\": KMeans(n_clusters=int(kwargs.get('n_clusters', 3))),\n",
    "            \"AGGLOMERATIVE\": AgglomerativeClustering(),\n",
    "            \"DBSCAN\": DBSCAN(),\n",
    "        }\n",
    "        algorithms = {\n",
    "            \"PREDICTION\": prediction_algorithms,\n",
    "            \"CLASSIFICATION\": classification_algorithms,\n",
    "            \"CLUSTERING\": clustering_algorithms\n",
    "        }\n",
    "        selected_algorithms = algorithms.get(operation_type.upper(), prediction_algorithms)\n",
    "        return selected_algorithms.get(algorithm_name.upper())\n",
    "\n",
    "def construct(command):\n",
    "    command_parts = [part for part in command.split(\" \") if part.strip()]\n",
    "    command_parts_upper = [part.upper() for part in command_parts]  # Convert command parts to uppercase\n",
    "\n",
    "    operation_types = [\"PREDICTION\", \"CLASSIFICATION\", \"CLUSTERING\"]\n",
    "\n",
    "    operation_type = command_parts[command_parts_upper.index(\"FOR\") + 1]\n",
    "    dataset_train_name = command_parts[command_parts_upper.index(\"FROM\") + 1].split(';')[0]\n",
    "    model_name = command_parts[command_parts_upper.index(\"CONSTRUCT\") + 1]\n",
    "\n",
    "    if \"ALGORITHM\" in command_parts_upper:\n",
    "        algorithm_name = command_parts[command_parts_upper.index(\"ALGORITHM\")+ 1] \n",
    "    else :\n",
    "        algorithm_name='AUTO_ML'\n",
    "\n",
    "    features = command_parts[command_parts_upper.index(\"FEATURES\") + 1].split(',')    \n",
    "\n",
    "    # connection_string = os.getenv(\"POSTGES_URL\")\n",
    "    query = f'SELECT * FROM \"{dataset_train_name}\"'\n",
    "    conn = create_engine(connection_string)\n",
    "\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    X = df[features]\n",
    "    y = None\n",
    "\n",
    "    global model, accuracy, label_name, response\n",
    "    response = {'text': '', 'graph': '', 'table': ''}\n",
    "    model = None \n",
    "    accuracy = None\n",
    "\n",
    "    if operation_type != \"CLUSTERING\":\n",
    "        target = command_parts[command_parts_upper.index(\"TARGET\") + 1]\n",
    "        y = df[target]\n",
    "\n",
    "    if y is not None and operation_type.upper() != \"CLUSTERING\":\n",
    "        test_s = float(command_parts[command_parts_upper.index(\"TEST\") + 2]) if \"TEST\" in command_parts_upper else 20\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test_s/100, random_state=42)\n",
    "        model = select_algorithm(operation_type, algorithm_name.upper())\n",
    "        if not algorithm_name:   algorithm_name='AUTO_ML'\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        try:\n",
    "            with open(f\"{model_name}.pkl\", 'wb') as file:\n",
    "                pickle.dump(model, file)\n",
    "            response['text'] += f\"Model {model_name} is created as name {model_name}.pkl. \"\n",
    "        except Exception as e:\n",
    "            response['text'] += f\"Error occurred while saving model {model_name}: {e}. \"\n",
    "        if \"TPOT\" in str(model): \n",
    "            response['text'] += f\"{json.dumps(str(model.fitted_pipeline_.steps[0]))}. \"\n",
    "        if operation_type.upper() == \"CLASSIFICATION\" :\n",
    "            accuracy = accuracy_score(y_test, y_pred)*100\n",
    "            response['text'] += f\"Accuracy of model {model_name} is {accuracy} .\"\n",
    "            print(response['text'])\n",
    "        elif operation_type.upper() == \"PREDICTION\":\n",
    "            accuracy = r2_score(y_test, y_pred)*100\n",
    "            response['text'] += f\"R-squared value of model {model_name} is {accuracy} .\"\n",
    "            print(\"R^2 Score:\", accuracy)\n",
    "  \n",
    "    else:\n",
    "        n_cluster = command_parts[command_parts_upper.index(\"CLUSTER\")+2] if \"CLUSTER\"  in command_parts_upper else 3\n",
    "        if algorithm_name == 'default':\n",
    "            algorithm_name = KMeans\n",
    "        model = select_algorithm(operation_type, algorithm_name.upper(), n_clusters=n_cluster)\n",
    "        X = pd.DataFrame(X.select_dtypes(include=[np.number]))\n",
    "        model.fit(X)\n",
    "        try:\n",
    "            with open(f\"{model_name}.pkl\", 'wb') as file:\n",
    "                pickle.dump(model, file)\n",
    "            response['text'] = f\"Model {model_name} is created as name {model_name}.pkl. \"\n",
    "        except Exception as e:\n",
    "            response['text'] = f\"Error occurred while saving model {model_name}: {e}. \"\n",
    "        print(response)\n",
    "\n",
    "# Example command and connection string\n",
    "command = \"CONSTRUCT LR_Boston AS SUPERVISED FOR PREDICTION on TARGET medv FEATURES age,rad ALGORITHM LR  TEST ON .3 FROM Boston;\"\n",
    "connection_string = \"postgresql://postgres:1234@localhost:5432/DL4ML\"  # os.getenv(\"POSTGES_URL\")\n",
    "\n",
    "construct(command)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
