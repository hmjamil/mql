{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display result function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select algorithm function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query and Postgresql set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "command=\"GENERATE  CLASSIFICATION Class BEST ALGORITHM KNN WITH ACCURACY 0 LABEL ProductID FEATURES CAtomCount,TotalAtomCount,HAtomCount FROM combined ;\"\n",
    "connection_string = \"postgresql://postgres:1234@localhost:5432/DL4ML\" #os.getenv(\"POSTGES_URL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans\n",
    "import sqlalchemy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from tpot import TPOTRegressor, TPOTClassifier\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "import base64\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans\n",
    "import sqlalchemy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from tpot import TPOTRegressor, TPOTClassifier\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def select_algorithm(operation_type, algorithm_name='AUTO_ML', **kwargs):\n",
    "    if algorithm_name == 'AUTO_ML':\n",
    "        if operation_type.upper() == \"PREDICTION\":\n",
    "            tpot_regressor = TPOTRegressor(generations=2, population_size=5, verbosity=2)\n",
    "            return tpot_regressor\n",
    "        elif operation_type.upper() == \"CLASSIFICATION\":\n",
    "            tpot_classifier = TPOTClassifier(generations=1, population_size=5, verbosity=2)\n",
    "            return tpot_classifier\n",
    "\n",
    "    print(algorithm_name, operation_type)\n",
    "    # Scikit-learn models\n",
    "    prediction_algorithms = {\n",
    "        \"LR\": LinearRegression(),\n",
    "        \"RF\": RandomForestRegressor(),\n",
    "        \"KNN\": KNeighborsRegressor(),\n",
    "    }\n",
    "    classification_algorithms = {\n",
    "        \"LOG\": LogisticRegression(),\n",
    "        \"RFC\": RandomForestClassifier(),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "    }\n",
    "    clustering_algorithms = {\n",
    "        \"KMEANS\": KMeans(n_clusters=(int(kwargs.get('n_clusters')) if kwargs.get('n_clusters') else 3)),\n",
    "        \"AGGLOMERATIVE\": AgglomerativeClustering(),\n",
    "        \"DBSCAN\": DBSCAN(),\n",
    "    }\n",
    "    algorithms = {\n",
    "        \"PREDICTION\": prediction_algorithms,\n",
    "        \"CLASSIFICATION\": classification_algorithms,\n",
    "        \"CLUSTERING\": clustering_algorithms\n",
    "    }\n",
    "    selected_algorithms = algorithms.get(operation_type.upper(), prediction_algorithms)\n",
    "    return selected_algorithms.get(algorithm_name.upper())\n",
    "def display_results(operation_type, y_test=None, y_pred=None, model=None, features=None, df=None):\n",
    "    if operation_type.upper() == \"PREDICTION\":\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()])\n",
    "        plt.xlabel('Measured')\n",
    "        plt.ylabel('Predicted')\n",
    "        plt.title('Actual vs Predicted Values')\n",
    "    elif operation_type.upper() == \"CLASSIFICATION\":\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix')\n",
    "    elif operation_type.upper() == \"CLUSTERING\":\n",
    "        if len(features) >= 2:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.scatterplot(data=pd.DataFrame(df), x=features[0], y=features[1], hue='Class', palette='viridis')\n",
    "            plt.scatter(model.cluster_centers_[:, 0], model.cluster_centers_[:, 1], s=rcParams['lines.markersize'] ** 2 ,c='red', label='Centroids')\n",
    "            plt.title('Clustering Results')\n",
    "            plt.legend(title=\"Cluster\")\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "    plt.savefig(buffer, format='png')\n",
    "    # url = os.path.join(os.path.dirname(__file__), f\"../graph/graph_.png\")\n",
    "    # plt.savefig(url, format='png')\n",
    "    buffer.seek(0)\n",
    "    # plot_data = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "    plt.show()\n",
    "    # plt.close()\n",
    "    # return plot_data\n",
    "def train_and_evaluate_sklearn(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, 'score'):\n",
    "        score = model.score(X_test, y_test)\n",
    "    else:\n",
    "        score = r2_score(y_test, y_pred)\n",
    "    return y_pred, score\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, classification=False):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "        self.classification = classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        if self.classification:\n",
    "            x = torch.softmax(x, dim=1)  # Use softmax for classification\n",
    "        return x\n",
    "\n",
    "def train_and_evaluate_torch(model, X_train, X_test, y_train, y_test, epochs=3, learning_rate=0.001, classification=False):\n",
    "    # Select appropriate criterion\n",
    "    criterion = nn.CrossEntropyLoss() if classification else nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Convert data to tensors\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.long if classification else torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.long if classification else torch.float32)\n",
    "    \n",
    "    # Create DataLoader\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            # Debugging prints\n",
    "            # print(f\"Epoch {epoch+1}, Batch shapes - X_batch: {X_batch.shape}, y_batch: {y_batch.shape}, outputs: {outputs.shape}\")\n",
    "\n",
    "            if classification:\n",
    "                loss = criterion(outputs, y_batch)\n",
    "            else:\n",
    "                loss = criterion(outputs.squeeze(), y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_tensor = model(X_test_tensor)\n",
    "        # # Debugging prints\n",
    "        # print(f\"Evaluation shapes - X_test_tensor: {X_test_tensor.shape}, y_test_tensor: {y_test_tensor.shape}, y_pred_tensor: {y_pred_tensor.shape}\")\n",
    "\n",
    "        if classification:\n",
    "            y_pred = torch.argmax(y_pred_tensor, dim=1).numpy()\n",
    "        else:\n",
    "            y_pred = y_pred_tensor.numpy().flatten()\n",
    "\n",
    "        if classification:\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "            return y_pred, accuracy\n",
    "        else:\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            print(f\"R² Score: {r2}\")\n",
    "            return y_pred, r2\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "def train_and_evaluate_tf(model, X_train, X_test, y_train, y_test, epochs=3, classification=False):\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Ensure y_test is flattened if it's a single-column 2D array\n",
    "    if y_test.ndim > 1 and y_test.shape[1] == 1:\n",
    "        y_test = y_test.flatten()\n",
    "\n",
    "    if classification:\n",
    "        # For classification, ensure predictions are argmaxed\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        # Ensure y_test and y_pred have the same shape\n",
    "        assert y_test.shape == y_pred.shape, f\"Shapes of y_test {y_test.shape} and y_pred {y_pred.shape} do not match.\"\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        return y_pred, accuracy\n",
    "    else:\n",
    "        # For regression, flatten the predictions\n",
    "        y_pred = y_pred.flatten()\n",
    "        # Ensure y_test and y_pred have the same shape\n",
    "        assert y_test.shape == y_pred.shape, f\"Shapes of y_test {y_test.shape} and y_pred {y_pred.shape} do not match.\"\n",
    "        # Calculate R^2 score\n",
    "        score = r2_score(y_test, y_pred)\n",
    "        return y_pred, score\n",
    "\n",
    "def build_tf_model(input_dim, output_dim, classification):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_dim),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(output_dim, activation='softmax' if classification else None)\n",
    "    ])\n",
    "    loss = 'sparse_categorical_crossentropy' if classification else 'mse'\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'] if classification else ['mae'])\n",
    "    return model\n",
    "\n",
    "def load_over_df(df_name):\n",
    "    url = os.path.join(os.path.dirname(__file__), f\"../../data/files/{df_name}.csv\")\n",
    "    return pd.read_csv(url)\n",
    "def load_saved_model(model_name):\n",
    "    url = os.path.join(os.path.dirname(__file__), f\"../model/{model_name}.pkl\")\n",
    "    try:\n",
    "        with open(url, 'rb') as file:\n",
    "            model = pickle.load(file)   \n",
    "    except:\n",
    "        response[\"text\"] = f\"Model: [{model_name}] Not found.\"\n",
    "        return response\n",
    "    \n",
    "def generate(command):\n",
    "    global model, accuracy, label_name, response\n",
    "    response = {'text': [], 'graph': '', 'table': ''}\n",
    "    command_parts = [part for part in command.split(\" \") if part.strip()]\n",
    "    try:\n",
    "        operation_types = [\"PREDICTION\", \"CLASSIFICATION\", \"CLUSTERING\"]\n",
    "        operation_type = next((word for word in operation_types if word in command), \"PREDICTION\")\n",
    "        dataset_train_name = command_parts[command_parts.index(\"FROM\") + 1].split(';')[0]\n",
    "        features = command_parts[command_parts.index(\"FEATURES\") + 1].split(',')\n",
    "        algorithm_name = command_parts[command_parts.index(\"ALGORITHM\") + 1] if \"ALGORITHM\" in command_parts else None\n",
    "\n",
    "    except Exception as e:\n",
    "        response = {'text': str(e), 'graph': '', 'table': ''}\n",
    "        return response\n",
    "  \n",
    "    try:\n",
    "        connection_string = \"postgresql://postgres:1234@localhost:5432/DL4ML\" #os.getenv(\"POSTGES_URL\")\n",
    "        query = f'SELECT * FROM \"{dataset_train_name}\"'\n",
    "        conn = create_engine(connection_string)\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        X = df[features]\n",
    "    except sqlalchemy.exc.ProgrammingError as e:\n",
    "        error_message = str(e.orig)  # Extract the original exception message\n",
    "        response['text'] = f\"Error Occurred! {error_message}\"\n",
    "        return response\n",
    "    \n",
    "    y = None\n",
    "    model = None\n",
    "    accuracy = None\n",
    "    label_encoder = LabelEncoder()\n",
    "    if operation_type != \"CLUSTERING\":\n",
    "        if operation_type.upper() == \"CLASSIFICATION\":\n",
    "            target = command_parts[command_parts.index(\"CLASSIFICATION\") + 1]\n",
    "        elif operation_type.upper() == \"PREDICTION\":\n",
    "            target = command_parts[command_parts.index(\"PREDICTION\") + 1]\n",
    "        y = df[target]\n",
    "        if operation_type.upper() == \"CLASSIFICATION\":\n",
    "            y = label_encoder.fit_transform(y)\n",
    "    if isinstance(y, np.ndarray):\n",
    "        y = pd.Series(y)\n",
    "    if \"OVER\" in command:\n",
    "        df = load_over_df(command_parts[command_parts.index('OVER') + 1])\n",
    "        if \"USING MODEL\" in command.upper():\n",
    "            load_saved_model(command_parts[command_parts.index(\"MODEL\") + 1] if \"MODEL\" in command_parts else \"iris_knn\")\n",
    "        else:\n",
    "            test_s = float(command_parts[command_parts.index(\"TEST\") + 2]) if \"TEST\" in command_parts else 20\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_s/100, random_state=42)\n",
    "            model = select_algorithm(operation_type, algorithm_name.upper())\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        X = df[features]\n",
    "        y_test = df[target]\n",
    "        y_pred = model.predict(df[features])\n",
    "        score = r2_score(y_test, y_pred)\n",
    "        accuracy = score\n",
    "        # display_results(operation_type, y_test, y_pred)\n",
    "    \n",
    "    elif \"USING MODEL\" in command.upper():\n",
    "        model_name=command_parts[command_parts.index(\"MODEL\") + 1] if \"MODEL\" in command_parts else \"iris_knn\"\n",
    "        load_saved_model(model_name)\n",
    "        y_pred = model.predict(X)\n",
    "        response['text'] = f\"{model_name} results\"\n",
    "        response['graph'] = display_results(operation_type, y_test, y_pred)\n",
    "\n",
    "    elif \"BEST ALGORITHM\" in command.upper():\n",
    "        try:\n",
    "            algorithm_name = command_parts[command_parts.index(\"ALGORITHM\") + 1] if \"ALGORITHM\" in command_parts else None\n",
    "        except Exception as err:\n",
    "            raise err\n",
    "        test_s = float(command_parts[command_parts.index(\"TEST\") + 2]) if \"TEST\" in command_parts else 20\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_s/100, random_state=42)\n",
    "        \n",
    "        # Scale the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        models = {\n",
    "            'sklearn': select_algorithm(operation_type, algorithm_name),\n",
    "            'pytorch': SimpleNN(X_train.shape[1], len(np.unique(y_train)) if operation_type.upper()==\"CLASSIFICATION\" else 1,classification= operation_type.upper()==\"CLASSIFICATION\"),\n",
    "            'tensorflow': build_tf_model(X_train.shape[1], len(np.unique(y_train)) if operation_type.upper()==\"CLASSIFICATION\" else 1,classification= operation_type.upper()==\"CLASSIFICATION\")\n",
    "        }\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Sklearn\n",
    "        y_pred_sklearn, score_sklearn = train_and_evaluate_sklearn(models['sklearn'], X_train, X_test, y_train, y_test)\n",
    "        results['sklearn'] = score_sklearn\n",
    "        # print(score_sklearn)\n",
    "        \n",
    "        # TensorFlow\n",
    "        y_pred_torch, score_torch = train_and_evaluate_torch(models['pytorch'], X_train, X_test, y_train, y_test, epochs=3,classification= operation_type.upper()==\"CLASSIFICATION\")\n",
    "\n",
    "        results['tensorflow'] = score_torch\n",
    "        # print(\"complete tensor\")\n",
    "        \n",
    "        # PyTorch\n",
    "        y_pred_tf, score_tf = train_and_evaluate_tf(models['tensorflow'], X_train, X_test, y_train, y_test,epochs=3,classification= operation_type.upper()==\"CLASSIFICATION\")\n",
    "        results['pytorch'] = score_tf\n",
    "        response[\"text\"].append(results)\n",
    "        # print(results)\n",
    "        best_framework = max(results, key=results.get)\n",
    "        best_score = results[best_framework]\n",
    "        \n",
    "        response['text'].append(f\"Best algorithm: {best_framework} and algorithm {algorithm_name}  with score: {best_score}\")\n",
    "        if \"DISPLAY\" in command_parts: \n",
    "            if best_framework == 'sklearn':\n",
    "                response['graph'] = display_results(operation_type, y_test, y_pred_sklearn)\n",
    "            elif best_framework == 'pytorch':\n",
    "                response['graph'] = display_results(operation_type, y_test, y_pred_torch)\n",
    "            else:\n",
    "                response['graph'] = display_results(operation_type, y_test, y_pred_tf)\n",
    "        \n",
    "    elif \"ALGORITHM\" in command:\n",
    "        print(\"in a\")\n",
    "        model = select_algorithm(operation_type, algorithm_name)\n",
    "        test_s = float(command_parts[command_parts.index(\"TEST\") + 2]) if \"TEST\" in command_parts else 20\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_s/100, random_state=42)\n",
    "        \n",
    "        if isinstance(model, (LogisticRegression, RandomForestClassifier, KNeighborsClassifier)):\n",
    "            y_pred, score = train_and_evaluate_sklearn(model, X_train, X_test, y_train, y_test)\n",
    "        else:\n",
    "            response['text'] = f\"Selected algorithm {algorithm_name} is not supported.\"\n",
    "            return response\n",
    "        \n",
    "        response['text'].append( f\"{algorithm_name} algorithm results with score: {score}\")\n",
    "        response['graph'] = display_results(operation_type, y_test, y_pred)\n",
    "\n",
    "    print(\"output\")\n",
    "    # response['table'] = df.to_dict(orient=\"records\")\n",
    "    print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CLASSIFICATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pyhton_project\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9085746734809768\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "output\n",
      "           Epsilon  CAtomCount  TotalAtomCount  HAtomCount  \\\n",
      "0      3801.893963          10              18           8   \n",
      "1      5370.317964          13              30          16   \n",
      "2      5623.413252          12              27          14   \n",
      "3      5495.408739          16              39          22   \n",
      "4      6025.595861          16              39          22   \n",
      "...            ...         ...             ...         ...   \n",
      "8797  80000.000000          28              75          35   \n",
      "8798  20000.000000          43             106          60   \n",
      "8799  65000.000000          32              71          31   \n",
      "8800  80000.000000          33              78          33   \n",
      "8801  80000.000000          26              65          29   \n",
      "\n",
      "      Longest Carbon Chain  Aromatic Atom Count  Max Distance  Bonds Count  \\\n",
      "0                        0                   10             5           11   \n",
      "1                        1                   10             6           15   \n",
      "2                        1                   10             6           14   \n",
      "3                        4                   10             9           18   \n",
      "4                        3                   10             7           18   \n",
      "...                    ...                  ...           ...          ...   \n",
      "8797                     2                   16            15           43   \n",
      "8798                    18                   20            27           49   \n",
      "8799                     7                   20            15           44   \n",
      "8800                     2                   26            16           48   \n",
      "8801                     2                   20            16           38   \n",
      "\n",
      "      Rdkit Descriptor Chi0  Rdkit Descriptor Chi0N  ...  \\\n",
      "0                  6.811555                5.618802  ...   \n",
      "1                 10.181798                9.041452  ...   \n",
      "2                  9.259149                8.118802  ...   \n",
      "3                 12.303119               11.162772  ...   \n",
      "4                 12.681798               11.541452  ...   \n",
      "...                     ...                     ...  ...   \n",
      "8797              28.863232               22.994779  ...   \n",
      "8798              32.237783               29.243258  ...   \n",
      "8799              28.277446               22.484857  ...   \n",
      "8800              32.888176               25.242222  ...   \n",
      "8801              26.457455               20.654709  ...   \n",
      "\n",
      "      Bond Chain-Se Atom Count  Na Atom Count  Fe Atom Count  Ru Atom Count  \\\n",
      "0                            0              0              0              0   \n",
      "1                            0              0              0              0   \n",
      "2                            0              0              0              0   \n",
      "3                            0              0              0              0   \n",
      "4                            0              0              0              0   \n",
      "...                        ...            ...            ...            ...   \n",
      "8797                         0              0              0              0   \n",
      "8798                         0              0              0              0   \n",
      "8799                         0              0              0              0   \n",
      "8800                         0              0              0              0   \n",
      "8801                         0              0              0              0   \n",
      "\n",
      "      Li Atom Count  Zn Atom Count  Mg Atom Count  Cu Atom Count  \\\n",
      "0                 0              0              0              0   \n",
      "1                 0              0              0              0   \n",
      "2                 0              0              0              0   \n",
      "3                 0              0              0              0   \n",
      "4                 0              0              0              0   \n",
      "...             ...            ...            ...            ...   \n",
      "8797              0              0              0              0   \n",
      "8798              0              0              0              0   \n",
      "8799              0              0              0              0   \n",
      "8800              0              0              0              0   \n",
      "8801              0              0              0              0   \n",
      "\n",
      "      Pd Atom Count  Class  \n",
      "0                 0    low  \n",
      "1                 0    low  \n",
      "2                 0    low  \n",
      "3                 0    low  \n",
      "4                 0    low  \n",
      "...             ...    ...  \n",
      "8797              0    low  \n",
      "8798              0    low  \n",
      "8799              0    low  \n",
      "8800              0    low  \n",
      "8801              0    low  \n",
      "\n",
      "[8802 rows x 249 columns]\n"
     ]
    }
   ],
   "source": [
    "generate(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
